+++
date = '2025-09-15T04:18:34+09:00'
draft = true
title = '最尤推定法'
+++

## 最尤推定法

あるパラメータの値を条件としたときにデータが実現する確率が最も高くなるパラメータの値を解とするのが最尤推定法である．パラメータを $\theta$，データを $X$とすると尤度は次のように定義できる．

$$
L(\theta) = p(X | \theta)
$$

**複雑なモデルになるとパラメータの解析解を求められないような場合も多く，そのような場合に最尤推定法が用いられる**．

最尤推定法の手順は次のようになる．

1. 推定したいモデルから尤度関数を定義する
2. 勾配降下法などの数値計算アルゴリズムを利用し尤度を最大化するパラメータの値を探索する
3. 尤度を最大化するパラメータを推定値とする

### 簡単な最尤推定の例: 歪なコインの表が出る確率

ここでとても簡単な例を用いて最尤推定を実際に行うことにする．

今，手元に歪な形をしたコインがあり，試しに５回投げてみたところ結果が次のようになった．

$$
X_1 = 表, X_2 = 表, X_3 = 裏, X_4 = 表, X_5 = 裏
$$

上記の得られたデータから，コインを投げたときに表が出る確率 $\theta$ を推定したい．

また，コインをN回投げたときに何回表が出るか，という事象は二項分布に従う．したがって，この推定の問題は， 二項分布$Bin(N=5, \theta)$のパラメータ $\theta$ を推定する問題とも解釈できる．

よって尤度関数は次のように定義できる．

$$
L(\theta) = p(X_1 = 表, X_2 = 表, X_3 = 裏, X_4 = 表, X_5 = 裏|\theta)= \frac{5!}{3!\cdot 2!}\theta^3\cdot(1-\theta)^2
$$

したがって，次の最大化問題を解けば良い．

$$
\max_{\theta} L(\theta) = \frac{5!}{3!\cdot2!}\theta^3\cdot(1-\theta)^2
$$

しかし，尤度関数の次数が高いため計算が複雑になってしまう．そこで，尤度の対数をとって対数尤度関数（Log Likelihood: LL） $LL(\theta)$を最大化する問題に書き換える．

$$
\max_{\theta}LL(\theta) = log10 + 3log\theta + 2log(1-\theta)
$$

対数尤度関数の一階条件を求めると，

$$
\frac{\partial LL(\theta)}{\partial \theta} = \frac{3}{\theta} - \frac{2}{1-\theta} = 0 \Rightarrow \theta = \frac{3}{5}
$$

### 簡単な最尤推定の例: 単回帰

$$
Y = \beta_0 + \beta_1 X + \varepsilon, \ \varepsilon \sim N(0, \sigma^2)
$$

次に，上記の単回帰モデルについて最尤推定の手順を確認したい．

まずパラメータ $\beta_0,\beta_1$と $x_i$条件とした $y_i$の条件付き確率密度関数を定義する．誤差項の定義は， $\varepsilon_i = y_i - \beta_0 - \beta_1 x_i$ であり，正規分布に従うので，

$$
p(y_i|x_i, \beta_0, \beta_1; \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}}\mathbb{exp}\left(-\frac{(y_i- \beta_0 - \beta_1 x_i)^2}{2\sigma^2} \right)
$$

観測したデータN個すべての確率密度を掛け合わせると単回帰モデルの尤度関数を定義できる．

$$
L(\beta_0, \beta_1; \sigma) = \prod_{i = 1}^{N} \frac{1}{\sqrt{2\pi\sigma^2}}\mathbb{exp}\left(-\frac{(y_i- \beta_0 - \beta_1 x_i)^2}{2\sigma^2} \right)
$$

対数尤度関数を定義すると，

$$
\begin{align*}LL(\beta_0, \beta_1; \sigma) &= \sum_{i = 1}^{N}-\frac{1}{2}log(2\pi\sigma^2) + \sum_{i = 1}^{N}\left(-\frac{(y_i- \beta_0 - \beta_1 x_i)^2}{2\sigma^2} \right)\\\\ &= \frac{N}{2}log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i = 1}^{N}(y_i- \beta_0 - \beta_1 x_i)^2  \end{align*}
$$

この対数尤度関数の第一項は，パラメータが存在しないため定数である．したがって，対数尤度関数の最大化問題を解く際には無視しても良い．第二項は，定数である $2\sigma^2$の逆数を無視して符号を正にすると，最小二乗法において最小化する目的関数と同様の式であることがわかる．したがって，単回帰モデルの最尤推定量と最小二乗推定量は一致することがわかる．

このように尤度関数が単純な形をしているときは，尤度関数を最大化するパラメータの値を解析的に計算することができる場合もある．

尤度関数が複雑な場合は解析解を得られないこともあるので，そのような場合は勾配降下法などのアルゴリズムをプログラムしコンピュータに数値解を探索させる．
